{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW7Ei9w3x82q"
   },
   "source": [
    "# ONCLUSIVE ML CHALLENGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSE-4SH8x82z"
   },
   "source": [
    "**Task:**\n",
    "Build an ML system to verify the veracity of claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsHwsg61x820"
   },
   "source": [
    "**Dataset:** PUBHEALTH is a comprehensive dataset for explainable automated fact-checking of\n",
    "public health claims. Each instance in the PUBHEALTH dataset has an associated\n",
    "veracity label (true, false, unproven, mixture). Furthermore each instance in the dataset\n",
    "has an explanation text field. The explanation is a justification for which the claim has\n",
    "been assigned a particular veracity label.\n",
    "\n",
    "**Dataset link:** https://huggingface.co/datasets/health_fact\n",
    "\n",
    "**Pretrained huggingface model used:** : https://huggingface.co/yikuan8/Clinical-Longformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ts8ZG_Qzx820"
   },
   "source": [
    "**Solution:** Modelled veracity verification as a multi-class classification problem. Given a pair of 'claim' and 'source or evidence' in natural language, one of the four veracity classes (true, false, unproven, mixture) is predicted. This is a natural language inference task where a claim is verified against evidence for veracity. Following steps were taken to build the ML system:\n",
    "1. The dataset was downloaded as train, validation and test splits using huggingface's datasets library.\n",
    "2. Data was preprocessed by combining 'claim' and 'main_text' columns and oversampling the minority class.\n",
    "3. A pretrained tokenizer was used to tokenize and convert input text into indices and attention masks.\n",
    "3. Since the data consists of very long text instances about health related claims, the Clinical-Longformer was used with a sequence classification head to train a multi-class classification network. \n",
    "\n",
    "`Clinical-Longformer is a clinical knowledge enriched version of Longformer that was further pre-trained using MIMIC-III clinical notes. It allows up to 4,096 tokens as the model input.` \n",
    "    \n",
    "**Distributed training was performed on a 4 gpu machine using huggingface's accelerate library.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYBuv0de_u3O"
   },
   "source": [
    "## Install the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YbdolZaE4uOj",
    "outputId": "e6a8ce50-4f16-4b32-da15-56dfa7f02907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
      "\u001b[K     |████████████████████████████████| 362 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 64.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 62.7 MB/s \n",
      "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 75.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 13.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 50.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 67.0 MB/s \n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 2.2 MB/s \n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[K     |████████████████████████████████| 144 kB 76.1 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 60.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IeCPdCdj_sSw",
    "outputId": "e26b6870-9e7d-41ef-9edc-54a2494b10b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /homes/vs001/anaconda3/lib/python3.8/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /homes/vs001/anaconda3/lib/python3.8/site-packages (from accelerate) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /homes/vs001/anaconda3/lib/python3.8/site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: psutil in /homes/vs001/anaconda3/lib/python3.8/site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /homes/vs001/anaconda3/lib/python3.8/site-packages (from accelerate) (1.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /homes/vs001/anaconda3/lib/python3.8/site-packages (from accelerate) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /homes/vs001/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->accelerate) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions in /homes/vs001/anaconda3/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9RfbVcTE6H1B",
    "outputId": "17371dbc-e1ed-4fb2-badd-b4d35e32c0e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB2r71_q_7Ct"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1V4Ev1Rn4qqk"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import pdb\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from tabulate import tabulate\n",
    "from IPython.display import clear_output\n",
    "from accelerate import Accelerator\n",
    "from accelerate import notebook_launcher\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight # n_samples / (n_classes * np.bincount(y))\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kEtekRhAAR7"
   },
   "source": [
    "## Download the dataset using huggingface datasets library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "f3cf6c67801c452aa39bd8eef078c8c0",
      "dc93ea75606a4f1b938e5749092d4c0a"
     ]
    },
    "id": "BuNaZZvo_sSx",
    "outputId": "4c5fdcd3-067e-4bee-edf6-f0cef753bfbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset health_fact (/homes/vs001/.cache/huggingface/datasets/health_fact/default/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc93ea75606a4f1b938e5749092d4c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data, val_data, test_data = datasets.load_dataset('health_fact', split =['train', 'validation', 'test']) # downloaded tain, validation and test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Gy6LxJ2AT8j"
   },
   "source": [
    "## Select useful columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy7nS21ezQz1"
   },
   "source": [
    "*   The dataset contains following columns: **'claim_id', 'claim', 'date_published', 'explanation', 'fact_checkers', 'main_text', 'sources', 'label', 'subjects'**\n",
    "\n",
    "*   As **'explanation'** is written by expert fact checkers, we cannot expect it to be available in production deployments. Thus, the model is built using **'claim'** and **'main_text'** columns only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyrHefRaASLt",
    "outputId": "856c3763-cf6a-4339-bd20-ec4df1122526"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /homes/vs001/.cache/huggingface/datasets/health_fact/default/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-79b9bc5aafb4c839.arrow\n",
      "Loading cached processed dataset at /homes/vs001/.cache/huggingface/datasets/health_fact/default/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-c1175cd62a8997bd.arrow\n",
      "Loading cached processed dataset at /homes/vs001/.cache/huggingface/datasets/health_fact/default/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-2d3e1cc1cb5b5a35.arrow\n"
     ]
    }
   ],
   "source": [
    "# make a list of all non-useful columns\n",
    "cols_to_remove = train_data.column_names\n",
    "cols_to_remove.remove(\"claim\") \n",
    "cols_to_remove.remove(\"main_text\")\n",
    "cols_to_remove.remove(\"label\")\n",
    "\n",
    "# remove non-useful columns\n",
    "train_data = train_data.remove_columns(cols_to_remove)\n",
    "val_data = val_data.remove_columns(cols_to_remove)\n",
    "test_data = test_data.remove_columns(cols_to_remove)\n",
    "\n",
    "# remove the undecided class '-1' as only four classes need to be modelled\n",
    "train_data = train_data.filter(lambda example, idx: example['label'] > -1, with_indices=True)\n",
    "val_data = val_data.filter(lambda example, idx: example['label'] > -1, with_indices=True)\n",
    "test_data = test_data.filter(lambda example, idx: example['label'] > -1, with_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JaE77Bh1l2b"
   },
   "source": [
    "## Check for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVNusOY9x826"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data) # convert training data to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mo1tdxCEx826",
    "outputId": "a6d54f2b-f2e1-40c5-b06b-09b44186eca1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    5078\n",
       "0    3001\n",
       "1    1434\n",
       "3     291\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DK5CaSa-1vPP"
   },
   "source": [
    "### **Note:** We find that there is huge class imbalance with the majority class >15X frequent than the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJQPYUxGx826"
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df[train_df['label']==3].sample(frac=0.5), train_df]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNs847BC2MiH"
   },
   "source": [
    "#### **Note:** We oversmpled minority class to improve class imbalance. The oversampling ratio was obtained by experimenting with different values and monitoring validation performance. \n",
    "\n",
    "**This also helped avoid severely skewed class weights later to be used in the loss function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffbvxLC_x826",
    "outputId": "664f3979-4587-49b2-d865-52ff010a2eb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    5078\n",
       "0    3001\n",
       "1    1434\n",
       "3     437\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qf4q5y0lx827"
   },
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df) # convert pandas dataframe back to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMKwqJY7AjK6"
   },
   "source": [
    "## Load pretrained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QwgN_drAhRD"
   },
   "outputs": [],
   "source": [
    "checkpoint = \"yikuan8/Clinical-Longformer\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint) # loaded pretrained tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZOw5DDJA_M8"
   },
   "source": [
    "## Join claim and main_text with seperator token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKwib0T9BLpL"
   },
   "outputs": [],
   "source": [
    "def get_text(example):\n",
    "    example['text'] = ' '.join([example['claim'], tokenizer.sep_token, example['main_text']]) # join 'claim' and 'main_text' in that order, with the seperator token recognized by above tokenizer\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "5ede29eae3f64180a9d9752b4ef530c3",
      "31f167c48b4e41549cdc954b4d8a21d4",
      "fab2f2a04e6143c8b6b237c6046fab5a"
     ]
    },
    "id": "eFx8pOAPA-LK",
    "outputId": "c731ca03-b503-4953-bea9-69caf9f2184b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function get_text at 0x7f68e687c1f0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ede29eae3f64180a9d9752b4ef530c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9950 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f167c48b4e41549cdc954b4d8a21d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1214 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab2f2a04e6143c8b6b237c6046fab5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1233 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply concatenation on all the data splits\n",
    "train_data = train_data.map(get_text)\n",
    "val_data = val_data.map(get_text)\n",
    "test_data = test_data.map(get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUB7XQBhBZAJ"
   },
   "source": [
    "## Convert text to indices and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "473ccec939194f9881aa1f78354691eb",
      "bca62e250c6f4e668f210808816c8f9c",
      "cf2efa00654b411b98cd61489d8c4c3b"
     ]
    },
    "id": "h5OOCbAKBXwL",
    "outputId": "1ca12d52-c6fc-4bd7-98d3-4febee479b39"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473ccec939194f9881aa1f78354691eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca62e250c6f4e668f210808816c8f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2efa00654b411b98cd61489d8c4c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizing and obtaining input vectors for concatenated text\n",
    "def tokenization(batched_text):\n",
    "    return tokenizer(batched_text['text'], padding = 'max_length', truncation=True, max_length = 1024) # maximum allowed length of input is 1024\n",
    "\n",
    "train_data = train_data.map(tokenization, batched = True, batch_size = len(train_data))\n",
    "val_data = val_data.map(tokenization, batched = True, batch_size = len(val_data))\n",
    "test_data = test_data.map(tokenization, batched = True, batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6NsaYnxBipQ"
   },
   "source": [
    "## Remove not-required columns and convert to pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um1Iz9wQBhr6",
    "outputId": "0090c1f1-74bc-44ff-8a88-e93237af2188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# now that we have input vectors, text columns can be dropped\n",
    "train_data = train_data.remove_columns(['claim', 'main_text', 'text']) \n",
    "val_data = val_data.remove_columns(['claim', 'main_text', 'text'])\n",
    "test_data = test_data.remove_columns(['claim', 'main_text', 'text'])\n",
    "train_data = train_data.rename_column(\"label\", \"labels\")\n",
    "val_data = val_data.rename_column(\"label\", \"labels\")\n",
    "test_data = test_data.rename_column(\"label\", \"labels\")\n",
    "print(train_data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-L9DGxYp_sSy"
   },
   "outputs": [],
   "source": [
    "# convert input dataset to pytorch tensors format\n",
    "train_data.set_format(\"torch\")\n",
    "val_data.set_format(\"torch\")\n",
    "test_data.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TfcyFQz4uUx"
   },
   "source": [
    "## Calculating class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0am7PbLx829",
    "outputId": "988418c4-9254-4c3b-9cc5-98c5d5a08db9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8289, 1.7347, 0.4899, 5.6922], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating class weights as the labels are still imbalanced\n",
    "y_integers = [int(i['labels']) for i in train_data]\n",
    "class_weight_array = compute_class_weight('balanced', classes = np.unique(y_integers), y = y_integers)\n",
    "class_weights = torch.tensor(class_weight_array)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEqjzxz0B-g8"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_lVB-86DFFr"
   },
   "source": [
    "### Define metrics to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKWSY0BqDJJd"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(labels, preds):\n",
    "        _, _, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro') # micro f1\n",
    "        classification_report_dict = classification_report(labels, preds, output_dict=True) \n",
    "        f1_std = np.std([classification_report_dict[str(i)]['f1-score'] for i in set(labels)]) # standard deviation of f1-score per class\n",
    "        f1_macro = classification_report_dict['macro avg']['f1-score'] # macro f1\n",
    "        acc = accuracy_score(labels, preds) # accuracy\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1_micro': f1_micro,\n",
    "            'f1_macro': f1_macro,\n",
    "            'f1_std': f1_std\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wkb_cUK_D3K7"
   },
   "source": [
    "### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qS7mBJS-r1U"
   },
   "outputs": [],
   "source": [
    "def run_training_loop():\n",
    "    \n",
    "    #setup train dataloader\n",
    "    train_dataloader = DataLoader(\n",
    "    train_data, shuffle=True, batch_size=2\n",
    "    )\n",
    "\n",
    "    #setup validation dataloader\n",
    "    val_dataloader = DataLoader(\n",
    "        val_data, batch_size=2\n",
    "    )\n",
    "\n",
    "    # Load the pretrained Clinical-Longformer model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=4)\n",
    "    \n",
    "    num_epochs = 10 # total number of epochs\n",
    "    num_training_steps = num_epochs * len(train_dataloader) # total number of training steps\n",
    "    \n",
    "    grouped_params = model.parameters()\n",
    "    optimizer=AdamW(grouped_params, lr=1e-5) # optimizer for parameter tuning\n",
    "\n",
    "    # linear learning rate scheduler\n",
    "    lr_scheduler = get_scheduler(\n",
    "                                \"linear\",\n",
    "                            optimizer=optimizer,\n",
    "                            num_warmup_steps=int(0.05*num_training_steps),\n",
    "                            num_training_steps=num_training_steps,\n",
    "                            )\n",
    "    \n",
    "    accelerator = Accelerator() # initialized accelerator object to distribute training code\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights.float().to(accelerator.device)) # custom weighted loss function\n",
    "    \n",
    "    train_dataloader, model, optimizer, lr_scheduler  = accelerator.prepare(\n",
    "     train_dataloader, model, optimizer, lr_scheduler) # prepared objects required for distributed training\n",
    "    \n",
    "    tracked_metrics = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_losses = []\n",
    "        model.train()\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs['logits']\n",
    "            loss = criterion(logits, batch['labels']) # custom loss calculation\n",
    "#             loss = outputs.loss\n",
    "            accelerator.backward(loss) # distributed gradient accumulation\n",
    "            train_losses.append(loss.cpu()) # collecting loss for logging\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        labels_all = []\n",
    "        preds_all = []\n",
    "        val_losses = []\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "    #         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            # pdb.set_trace()\n",
    "            logits = outputs.logits\n",
    "            val_losses.append(outputs.loss.cpu()) # collecting loss for logging\n",
    "            predictions = torch.argmax(logits, dim=-1) # obtaining predictions from logits\n",
    "            labels = batch['labels'].cpu() # obtaining labels for the batch\n",
    "            # pdb.set_trace()\n",
    "            labels_all = labels_all + labels.tolist()\n",
    "            preds = predictions.cpu() # obtaining predictions for the batch\n",
    "            preds_all = preds_all + preds.tolist()\n",
    "            \n",
    "        metrics = compute_metrics(labels_all, preds_all) # get metrics to log\n",
    "\n",
    "        tracked_metrics.append([epoch, sum(train_losses)/len(train_losses), sum(val_losses)/len(val_losses), metrics['accuracy'], metrics['f1_micro'], metrics['f1_macro'], metrics['f1_std']])\n",
    "        clear_output(wait=True)\n",
    "        print(tabulate(tracked_metrics, headers=['EPOCH', 'Training Loss', 'Validation Loss', 'Val Accuracy', 'Val F1_micro', 'Val F1_macro', 'Val F1_std'])) # log metrics\n",
    "        \n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(f'dist_train_longformer_clinical_oversamped_balanced/{epoch}') # save the after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWSPIRHL_sSz",
    "outputId": "3c9d9172-51b2-46a8-a2fb-ed25587e5292",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EPOCH    Training Loss    Validation Loss    Val Accuracy    Val F1_micro    Val F1_macro    Val F1_std\n",
      "-------  ---------------  -----------------  --------------  --------------  --------------  ------------\n",
      "      0        0.949207            0.640989        0.724876        0.724876        0.563889      0.24084\n",
      "      1        0.700016            0.580641        0.73888         0.73888         0.625849      0.182257\n",
      "      2        0.531183            0.581147        0.73229         0.73229         0.636882      0.168691\n",
      "      3        0.455887            0.59807         0.764415        0.764415        0.656159      0.17186\n",
      "      4        0.357285            0.671122        0.779242        0.779242        0.685651      0.17155\n",
      "      5        0.251612            0.720104        0.769357        0.769357        0.667255      0.180561\n",
      "      6        0.205921            0.852754        0.766063        0.766063        0.678264      0.160546\n",
      "      7        0.14258             0.885815        0.775947        0.775947        0.665209      0.174406\n",
      "      8        0.110806            0.908174        0.783361        0.783361        0.685726      0.165416\n",
      "      9        0.0789179           0.948688        0.785008        0.785008        0.692351      0.160637\n"
     ]
    }
   ],
   "source": [
    "notebook_launcher(run_training_loop, num_processes=4) # launch distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDjPKFnx_sS2"
   },
   "source": [
    "**We note the following:**\n",
    "1. The training loss is decreasing well.\n",
    "2. The validation loss significantly increases after initially decreasing and fluctuating till epoch 3. The model is overfitting post epoch 3 .\n",
    "3. Epochs 1, 2 and 3 have almost same validation losses.\n",
    "4. Epoch 2 has the smallest standard deviation of f1 scores accross classes.\n",
    "\n",
    "As we do not have preference for any one class over another, the model with smallest standard deviation of f1 scores accross classes was chosen for testing and deployment.\n",
    "\n",
    "**EPOCH-2 is chosen as our best model**\n",
    "\n",
    "`EPOCH|    Training Loss|    Validation Loss|    Val Accuracy|    Val F1_micro|    Val F1_macro|    Val F1_std`\n",
    "-------  ---------------  -----------------  --------------  --------------  --------------  ------------\n",
    "  \n",
    "`      2 |           0.531183 |               0.581147 |           0.73229 |            0.73229 |            0.636882 |         0.168691`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52dO6Fq3EAZj"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJahd1ISx82_"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # get cuda device for inference on gpu if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf_uIQUox82_"
   },
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_data, batch_size=16) # get validation dataloader\n",
    "test_dataloader = DataLoader(test_data, batch_size=16) # get test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGhqOj5qx82_"
   },
   "outputs": [],
   "source": [
    "def prediction_loop(loader, model):\n",
    "    tracked_metrics = []\n",
    "    labels_all = []\n",
    "    preds_all = []\n",
    "    val_losses = []\n",
    "    for batch in loader:\n",
    "                batch = {k: v.to(device) for k, v in batch.items()} # put batch to gpu devide if available\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**batch)\n",
    "                # pdb.set_trace()\n",
    "                logits = outputs.logits\n",
    "                val_losses.append(outputs.loss.cpu())\n",
    "                predictions = torch.argmax(logits, dim=-1)\n",
    "                labels = batch['labels'].cpu()\n",
    "                # pdb.set_trace()\n",
    "                labels_all = labels_all + labels.tolist()\n",
    "                preds = predictions.cpu()\n",
    "                preds_all = preds_all + preds.tolist()\n",
    "    metrics = compute_metrics(labels_all, preds_all)\n",
    "    tracked_metrics.append([sum(val_losses)/len(val_losses), metrics['accuracy'], metrics['f1_micro'], metrics['f1_macro'], metrics['f1_std']])\n",
    "    print(tabulate(tracked_metrics, headers=['Validation Loss', 'Val Accuracy', 'Val F1_micro', 'Val F1_macro', 'Val f1_std']))    \n",
    "    print(classification_report(labels_all,  preds_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvkyV3UEx82_"
   },
   "outputs": [],
   "source": [
    "def get_metrics(path):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(path, num_labels=4)\n",
    "    model.to(device)\n",
    "    print('=======================','val','=======================')\n",
    "    prediction_loop(val_dataloader, model)\n",
    "    print('=======================','test','=======================')\n",
    "    prediction_loop(test_dataloader, model)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLkI1s9Ox82_",
    "outputId": "b12d0a2a-5194-4ee0-9640-a7ba9fc3351d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= val =======================\n",
      "  Validation Loss    Val Accuracy    Val F1_micro    Val F1_macro    Val f1_std\n",
      "-----------------  --------------  --------------  --------------  ------------\n",
      "          0.58121         0.73229         0.73229        0.636882      0.168691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67       380\n",
      "           1       0.35      0.70      0.46       164\n",
      "           2       0.96      0.85      0.90       629\n",
      "           3       0.44      0.63      0.52        41\n",
      "\n",
      "    accuracy                           0.73      1214\n",
      "   macro avg       0.64      0.69      0.64      1214\n",
      "weighted avg       0.81      0.73      0.75      1214\n",
      "\n",
      "======================= test =======================\n",
      "  Validation Loss    Val Accuracy    Val F1_micro    Val F1_macro    Val f1_std\n",
      "-----------------  --------------  --------------  --------------  ------------\n",
      "         0.646326        0.729116        0.729116         0.64037      0.160688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71       388\n",
      "           1       0.41      0.69      0.51       201\n",
      "           2       0.94      0.81      0.87       599\n",
      "           3       0.40      0.56      0.47        45\n",
      "\n",
      "    accuracy                           0.73      1233\n",
      "   macro avg       0.64      0.67      0.64      1233\n",
      "weighted avg       0.79      0.73      0.75      1233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_metrics('models/2') # getting final performance of our best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKQu7EO3EQIi"
   },
   "source": [
    "### Final model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLBYUJt9BO-U"
   },
   "source": [
    "**Performance of the final model:**\n",
    "\n",
    "**Validation set:**\n",
    "\n",
    "Loss: 0.58121\n",
    "\n",
    "Micro F1: 0.73229\n",
    "\n",
    "Macro F1: 0.636882      \n",
    "\n",
    "False F1: 0.67\n",
    "\n",
    "Mixture F1: 0.46\n",
    "\n",
    "True F1: 0.90\n",
    "\n",
    "Unproven F1: 0.52\n",
    "\n",
    "\n",
    "**Test set:**\n",
    "\n",
    "Loss: 0.646326        \n",
    "\n",
    "Micro F1: 0.729116        \n",
    "\n",
    "Macro F1: 0.64037\n",
    "\n",
    "False F1: 0.71\n",
    "\n",
    "Mixture F1: 0.51\n",
    "\n",
    "True F1: 0.87\n",
    "\n",
    "Unproven F1: 0.47"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "onclusive_veracity_prediction_final_submission.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
